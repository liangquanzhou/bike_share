---
title: "Bay Area"
subtitle: "ðŸš´ <br/>Bike Share"
author: "Team 2: Five States"
date: "2017/10/01"
output:
  xaringan::moon_reader:
    lib_dir: libs
    nature:
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
---

```{r setup, include=FALSE}
options(htmltools.dir.version = FALSE)
options(servr.daemon = TRUE)
knitr::opts_chunk$set(echo = F, tidy = F, warning = F, message = F,
                      comment = "", tidy = F, fig.width = 10,
                      eval = require("DT", "tidyverse"))
library(tidyverse)
library(gridExtra)
library(DT)
```

# Background

- Bay Area Bike Share offers cheap, fast and on-demand service for the users in San Francisco who need commute to work or school, run errands and explore the city.  

- How to utilize data to optimize the operation which in turn to streamline the process and supply chain in order to satisfy customersâ€™ demands by analyzing the data that the company has would be the top priority of the company.

- We have tracking the usage of the rented bike in the past years which makes it available to analyze by using the historical data.

.footnote[
  Team member: Peng Gong, Qiaozhi Jiang, Xinyu Mou, Zhanfeng Shen, Liangquan Zhou
]
???

here is some thing in the notes

---

# Objects and Approach

1. Exploratory analysis:
  
  - When do people use the bike?
  
  - How long do people use the bike?
  
  - Which stations has more usage of bike?
  
2. Linear Regression:
  How does the weather affect the bike usage?

---

# Data

Data comes from [Ford GoBike](http://www.bayareabikeshare.com/datachallenge) open data source.

Contains 4 tables:

  1. station.csv
  
  2. trip.csv
  
  3. weather.csv
  
  4. status.csv 

We use the data from 08/2015 - 08/2016

---

### station.csv

67 records â€“ station ID, name, latitude, longitude, dockcount, city, installation date

```{r}
station <- read_csv("./../data/201608_station_data.csv") 
DT::datatable(
  head(station, 10),
  fillContainer = F, options = list(pageLength = 3, scrollX = T, dom = "tp"),
  rownames = F
)
```


---

### trip.csv

Approx. 314,000 records of individual trips

```{r}
trip <- read_csv("./../data/201608_trip_data.csv")
DT::datatable(
  head(trip, 10),
  fillContainer = F, options = list(pageLength = 3, scrollX = T, dom = "tp"),
  rownames = F
)
```

---

### weather.csv

1,830 records of daily weather by city

```{r}
weather <- read_csv("./../data/201608_weather_data.csv")
DT::datatable(
  head(weather, 10),
  fillContainer = F, options = list(pageLength = 3, scrollX = T, dom = "tp"),
  rownames = F
)
```

---
class: inverse, center, middle

# Exploratory Analysis

---

## Time and bike usage

```{r}
p1
```

???
with 1 year data - how does the bike usage affected the dates
 - weekday and weekend will affect
 - seems like season will affect, but actually is holiday (red dots with small value)

---

## Bike usage among a week

```{r}
p2
```

---

## Bike usage in a day

```{r}
p3
```

???

peak hours has the most usage

will weekday/weekends affect the usage in a day?

---

## Bike usage in a day

```{r}
p4
```

---

## Trip duration 

```{r}
gridExtra::grid.arrange(p5, p6, ncol = 1)
```

---

## Locations

```{r out.width='100%', fig.height=6, eval=require('leaflet')}
l8
```

---

## Bike usage in a city

Take San Jose as an example
```{r}
p7
```

---
class: inverse, center, middle

# Regression

## How does the weather affect the bike usage?

---

### weather.csv

```{r}
weather %>% glimpse
```

---

## Variable Selection

Response variable: `num of trips`

Possible predictor variables:

- `weekday`
- `mean_temperature_f`
- `precipitation_in`
- `mean_visibility_miles`
- `mean_humidity`
- `mean_wind_speed_mph`
- `cloud_cover`
- `events`

Use `regsubsets` function in `leaps` package for variable selection. Use San Francisco data.

---

## Diagnostic

```{r}
par(mfrow = c(2, 2), oma = c(0, 0, 2, 0))
plot(fit)
```

???

Residual Diagnostic:

1. Residual vs fitted has a pattern - transform on Y

1. qq plot - not normal - may be affected by extreme values

---

## Diagnostic

```{r}
p10
```

???

other factors could make model fail:

Seperated by weekday/weekend may not accurate. Should include national holidays 

---

## Diagnostic

Check weekdays with low usage
```{r}
DT::datatable(
  w1 %>% slice(1:18),
  fillContainer = F, options = list(pageLength = 5, scrollY = T, dom = "tp"),
  rownames = F
)
```

--

Treat national holidays as weekend, and we can get the model:

$$\sqrt{num\ of\ trips} = 18.685 - 35.562 weekend + 0.366 mean\ temperature +\\
1.534mean\ visibility\ miles - 5.91 events\ Rain - 5.767 events\ Rain\ Thunderstorm$$

???

we should exclude holidays. 

---

## Final Model

```{r}
summary(fit_holiday_adjust)
```

---

## Final Model 

```{r}
par(mfrow = c(2, 2), oma = c(0, 0, 2, 0))
plot(fit_holiday_adjust)
```

---
class: inverse, center, middle

# Thank You!
